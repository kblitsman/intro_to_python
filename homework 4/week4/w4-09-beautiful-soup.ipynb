{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n",
    "- great 'screen scraping' package\n",
    "- tons of interesting data on webpages designed for people, not programs\n",
    "- makes it easy to extract information from complex web pages and XML documents\n",
    "- soup reads in the page of interest, then you can query it\n",
    "- often can figure out what to do by playing interactively\n",
    "- works in unicode\n",
    "- new code should use BeautifulSoup version 4\n",
    "- [doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example:\n",
    "# Want to find all the headlines on the front page of the [New York Times](http://nyt.com)\n",
    "- but - key point - i don't want to work very hard!!!\n",
    "    - look at webpage source - html structure is quite complex - not interested in understanding it\n",
    "    - would be very difficult to do using text tools we have seen so far, like string.find() and regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'lxml' is a XML parser(parses HTML too)\n",
    "# must tell soup what unicode decoding to use\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import lxml\n",
    "\n",
    "nf2 = urllib.request.urlopen('http://nyt.com')\n",
    "sp = bs4.BeautifulSoup(nf2, 'lxml', from_encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headlines seem to be contained in 'h2' elements\n",
    "\n",
    "sp.findAll('h2')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 'h2' element\n",
    "\n",
    "h2 = sp.h2\n",
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can pull 'a' element out of 'h2'\n",
    "# this 'a' element is a picture\n",
    "\n",
    "a=h2.find('a')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try pulling the 'a' out of all 'h2' elements\n",
    "# looks like we get mostly headlines\n",
    "\n",
    "al=[h2.find('a') for h2 in sp.findAll(\"h2\")]\n",
    "al[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the 'a' link text \n",
    "\n",
    "[a.contents for a in al if a != None][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out images\n",
    "\n",
    "[a.contents for a in al if a != None and len(a)==1][:30]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
